[package]
name = "gllm"
version = "0.10.5"
edition = "2021"
authors = ["gllm contributors"]
license = "Apache-2.0"
description = "Pure Rust library for local embeddings, reranking, and text generation with MoE-optimized inference and aggressive performance tuning"
repository = "https://github.com/putao520/gllm"
homepage = "https://github.com/putao520/gllm"
keywords = ["embeddings", "reranking", "nlp", "ml", "rust"]
categories = ["algorithms", "science", "text-processing"]

[lib]
name = "gllm"
path = "src/lib.rs"

[[bin]]
name = "test_models"
path = "test_models.rs"

[[bin]]
name = "stress_test"
path = "stress_test.rs"

[features]
default = ["cpu"]
tokio = ["dep:tokio"]
wgpu = ["gllm-kernels/wgpu"]
cpu = ["gllm-kernels/cpu"]
cuda = ["gllm-kernels/cuda"]
wgpu-detect = ["dep:wgpu", "dep:pollster"]  # Enable GPU detection
quantized = []
gpu-quantized = ["quantized"]
paged-attention = []
flash-attention = []

[dependencies]
burn = { version = "0.20.0-pre.3", default-features = false, features = ["std", "wgpu", "candle", "ndarray"] }
gllm-kernels = { version = "0.1.2", default-features = false }
wgpu = { version = "26.0", optional = true }
pollster = { version = "0.4", optional = true }
burn-import = { version = "0.20.0-pre.3", default-features = false, features = ["safetensors"] }
hf-hub = { version = "0.4.3", default-features = false, features = ["ureq", "rustls-tls"] }
tokenizers = { version = "0.22.1", default-features = false, features = ["fancy-regex"] }
tokio = { version = "1", optional = true, features = ["rt-multi-thread", "macros", "sync"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
thiserror = "2"
log = "0.4"
dirs = "5"
safetensors = "0.4"
rand = "0.8"
half = "2.4"
memmap2 = "0.9"

[dev-dependencies]
criterion = "0.5"
tempfile = "3"

[[bench]]
name = "moe_layer"
harness = false

[[bench]]
name = "quantized_matmul"
harness = false
required-features = ["quantized"]
